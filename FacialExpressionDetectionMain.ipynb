{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM67DNJOWx+OVt/IbisAPDX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Narennnnn/EmoNet-Deep-Learning-for-Facial-Expression-Recognition/blob/main/FacialExpressionDetectionMain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "p1V288EQohk2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzDb1bE6qepT",
        "outputId": "57d6c5c2-59b3-4487-9565-8143583f8832"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXv4VpD_rbDP",
        "outputId": "a4aa3672-3046-40d0-e10d-d5d29cffa7d2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset.zip  \u001b[0m\u001b[01;34mfer2013\u001b[0m/  fer2013.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/Facial\\ Expression\\ Dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeYtMYv1rb5A",
        "outputId": "b08d0f93-32b0-46ae-b845-e1ae437f85f4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/Facial Expression Dataset/'\n",
            "/content/drive/MyDrive/Facial Expression Dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "serkd6Dswcq3",
        "outputId": "1963db6c-b5a7-48c0-a088-6a9050ff5fa9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Dataset.zip\n",
            "replace fer2013.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/Facial Expression Dataset/fer2013.csv'\n",
        "data = pd.read_csv(csv_path)\n",
        "\n",
        "image_paths = data['pixels'].values\n",
        "labels = data['emotion'].values\n"
      ],
      "metadata": {
        "id": "vntqkC0gxfjs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the image paths\n",
        "preprocessed_images = []\n",
        "for image_data in image_paths:\n",
        "    image = np.array(image_data.split(' '), dtype=np.uint8)\n",
        "    image = image.reshape((48, 48))\n",
        "    preprocessed_images.append(image)\n"
      ],
      "metadata": {
        "id": "TPisjCDPyGTu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the preprocessed data to NumPy arrays\n",
        "preprocessed_images = np.array(preprocessed_images)\n",
        "labels = np.array(labels)\n"
      ],
      "metadata": {
        "id": "rbUja4ENbUU8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the preprocessed data to NumPy arrays\n",
        "preprocessed_images = np.array(preprocessed_images)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "XAiwM5NT-ieI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation using ImageDataGenerator\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "mP579BbH_CSU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate augmented images and labels\n",
        "augmented_images = []\n",
        "augmented_labels = []\n",
        "for image, label in zip(preprocessed_images, labels):\n",
        "    image = np.expand_dims(image, axis=-1)  # Add an additional dimension for the channel\n",
        "    image = np.expand_dims(image, axis=0)  # Add an additional dimension for the batch\n",
        "    aug_iter = datagen.flow(image, save_to_dir=None, shuffle=False)\n",
        "    for aug_image in aug_iter:\n",
        "        augmented_images.append(aug_image[0])\n",
        "        augmented_labels.append(label)\n",
        "        break\n",
        "\n",
        "augmented_images = np.array(augmented_images)\n",
        "augmented_labels = np.array(augmented_labels)"
      ],
      "metadata": {
        "id": "u9PhVQNo_D63"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-validation-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(augmented_images, augmented_labels, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "f6kA9pBdyTyD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the deep learning model\n",
        "num_classes = len(np.unique(labels))\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 1)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "initial_learning_rate = 0.001\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=10000, decay_rate=0.9\n",
        ")\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "uBs1DgLq6tFK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Hk2Hhf55lzw",
        "outputId": "5a655bc4-92c4-4ef1-b696-2dd568cb7377"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "718/718 [==============================] - 279s 386ms/step - loss: 1.9877 - accuracy: 0.2826 - val_loss: 1.6811 - val_accuracy: 0.3197\n",
            "Epoch 2/10\n",
            "718/718 [==============================] - 270s 377ms/step - loss: 1.6081 - accuracy: 0.3697 - val_loss: 1.5889 - val_accuracy: 0.3826\n",
            "Epoch 3/10\n",
            "718/718 [==============================] - 271s 378ms/step - loss: 1.5122 - accuracy: 0.4143 - val_loss: 1.5371 - val_accuracy: 0.3925\n",
            "Epoch 4/10\n",
            "718/718 [==============================] - 271s 377ms/step - loss: 1.4282 - accuracy: 0.4495 - val_loss: 1.4690 - val_accuracy: 0.4296\n",
            "Epoch 5/10\n",
            "718/718 [==============================] - 270s 376ms/step - loss: 1.3514 - accuracy: 0.4793 - val_loss: 1.4357 - val_accuracy: 0.4429\n",
            "Epoch 6/10\n",
            "718/718 [==============================] - 268s 373ms/step - loss: 1.2655 - accuracy: 0.5204 - val_loss: 1.4915 - val_accuracy: 0.4472\n",
            "Epoch 7/10\n",
            "718/718 [==============================] - 261s 363ms/step - loss: 1.1580 - accuracy: 0.5605 - val_loss: 1.5322 - val_accuracy: 0.4394\n",
            "Epoch 8/10\n",
            "718/718 [==============================] - 262s 364ms/step - loss: 1.0247 - accuracy: 0.6177 - val_loss: 1.6297 - val_accuracy: 0.4286\n",
            "Epoch 9/10\n",
            "718/718 [==============================] - 261s 364ms/step - loss: 0.8763 - accuracy: 0.6754 - val_loss: 1.7087 - val_accuracy: 0.4401\n",
            "Epoch 10/10\n",
            "718/718 [==============================] - 254s 354ms/step - loss: 0.7059 - accuracy: 0.7393 - val_loss: 1.9788 - val_accuracy: 0.4343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Test Loss:', loss)\n",
        "print('Test Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgwQEpwyyfTE",
        "outputId": "54e6131f-24f5-49b8-bea5-757f417275ea"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 21s 94ms/step - loss: 1.9998 - accuracy: 0.4283\n",
            "Test Loss: 1.9998326301574707\n",
            "Test Accuracy: 0.4282529950141907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "y_pred = np.argmax(model.predict(X_test), axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gejh3eIUuoaF",
        "outputId": "f3f39d16-1d76-4cf6-eecc-db720ce73d9d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 19s 86ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate classification report\n",
        "target_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxERbxSb9Rul",
        "outputId": "87cc25c1-7053-42a0-8ceb-0ee7d9a6d20b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.32      0.39      0.35       985\n",
            "     Disgust       0.13      0.05      0.07       102\n",
            "        Fear       0.26      0.21      0.23      1043\n",
            "       Happy       0.61      0.67      0.64      1765\n",
            "         Sad       0.34      0.23      0.28      1210\n",
            "    Surprise       0.54      0.54      0.54       795\n",
            "     Neutral       0.38      0.45      0.41      1278\n",
            "\n",
            "    accuracy                           0.43      7178\n",
            "   macro avg       0.37      0.36      0.36      7178\n",
            "weighted avg       0.42      0.43      0.42      7178\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model in HDF5 format\n",
        "model.save('/content/drive/MyDrive/model.h5')"
      ],
      "metadata": {
        "id": "TRltMvkhZgC6"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}