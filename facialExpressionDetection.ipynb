{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmDoQgJy4ZnNbjXrsS7lP8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Narennnnn/EmoNet-Deep-Learning-for-Facial-Expression-Recognition/blob/main/facialExpressionDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1V288EQohk2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzDb1bE6qepT",
        "outputId": "391409d0-6a52-43ae-8079-33c24561da42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXv4VpD_rbDP",
        "outputId": "bb004b58-7eea-43a8-9bbb-03c8d3ffee25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/Facial\\ Expression\\ Dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeYtMYv1rb5A",
        "outputId": "faf90a66-ded2-4025-fcf0-efd8673c161c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Facial Expression Dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "serkd6Dswcq3",
        "outputId": "6eaafb16-8c0a-49d7-ff3c-de132f6d0cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Dataset.zip\n",
            "  inflating: fer2013.csv             \n",
            "  inflating: fer2013/fer2013.csv     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/Facial Expression Dataset/fer2013.csv'\n",
        "data = pd.read_csv(csv_path)\n",
        "\n",
        "image_paths = data['pixels'].values\n",
        "labels = data['emotion'].values\n"
      ],
      "metadata": {
        "id": "vntqkC0gxfjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the image paths\n",
        "preprocessed_images = []\n",
        "for image_data in image_paths:\n",
        "    image = np.array(image_data.split(' '), dtype=np.uint8)\n",
        "    image = image.reshape((48, 48))\n",
        "    preprocessed_images.append(image)\n"
      ],
      "metadata": {
        "id": "TPisjCDPyGTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the preprocessed data to NumPy arrays\n",
        "preprocessed_images = np.array(preprocessed_images)\n",
        "labels = np.array(labels)\n"
      ],
      "metadata": {
        "id": "N3WluGPZyQT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the preprocessed data to NumPy arrays\n",
        "preprocessed_images = np.array(preprocessed_images)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "XAiwM5NT-ieI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation using ImageDataGenerator\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "mP579BbH_CSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate augmented images and labels\n",
        "augmented_images = []\n",
        "augmented_labels = []\n",
        "for image, label in zip(preprocessed_images, labels):\n",
        "    image = np.expand_dims(image, axis=-1)  # Add an additional dimension for the channel\n",
        "    image = np.expand_dims(image, axis=0)  # Add an additional dimension for the batch\n",
        "    aug_iter = datagen.flow(image, save_to_dir=None, shuffle=False)\n",
        "    for aug_image in aug_iter:\n",
        "        augmented_images.append(aug_image[0])\n",
        "        augmented_labels.append(label)\n",
        "        break\n",
        "\n",
        "augmented_images = np.array(augmented_images)\n",
        "augmented_labels = np.array(augmented_labels)"
      ],
      "metadata": {
        "id": "u9PhVQNo_D63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-validation-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(augmented_images, augmented_labels, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "f6kA9pBdyTyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the deep learning model\n",
        "num_classes = len(np.unique(labels))\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 1)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "initial_learning_rate = 0.001\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=10000, decay_rate=0.9\n",
        ")\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "uBs1DgLq6tFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Hk2Hhf55lzw",
        "outputId": "68507a07-9763-4c7a-8692-85b2ddb7b528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "718/718 [==============================] - 274s 379ms/step - loss: 1.9800 - accuracy: 0.2777 - val_loss: 1.6648 - val_accuracy: 0.3532\n",
            "Epoch 2/10\n",
            "718/718 [==============================] - 278s 387ms/step - loss: 1.6232 - accuracy: 0.3629 - val_loss: 1.5923 - val_accuracy: 0.3811\n",
            "Epoch 3/10\n",
            "718/718 [==============================] - 278s 387ms/step - loss: 1.5241 - accuracy: 0.4079 - val_loss: 1.4992 - val_accuracy: 0.4241\n",
            "Epoch 4/10\n",
            "718/718 [==============================] - 277s 386ms/step - loss: 1.4377 - accuracy: 0.4462 - val_loss: 1.4497 - val_accuracy: 0.4342\n",
            "Epoch 5/10\n",
            "718/718 [==============================] - 265s 370ms/step - loss: 1.3477 - accuracy: 0.4870 - val_loss: 1.4517 - val_accuracy: 0.4458\n",
            "Epoch 6/10\n",
            "718/718 [==============================] - 261s 363ms/step - loss: 1.2524 - accuracy: 0.5245 - val_loss: 1.4708 - val_accuracy: 0.4589\n",
            "Epoch 7/10\n",
            "718/718 [==============================] - 270s 376ms/step - loss: 1.1455 - accuracy: 0.5682 - val_loss: 1.4870 - val_accuracy: 0.4450\n",
            "Epoch 8/10\n",
            "718/718 [==============================] - 270s 376ms/step - loss: 1.0110 - accuracy: 0.6185 - val_loss: 1.6223 - val_accuracy: 0.4467\n",
            "Epoch 9/10\n",
            "718/718 [==============================] - 267s 372ms/step - loss: 0.8589 - accuracy: 0.6774 - val_loss: 1.7661 - val_accuracy: 0.4378\n",
            "Epoch 10/10\n",
            "718/718 [==============================] - 270s 377ms/step - loss: 0.7066 - accuracy: 0.7398 - val_loss: 1.9756 - val_accuracy: 0.4316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Test Loss:', loss)\n",
        "print('Test Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgwQEpwyyfTE",
        "outputId": "84840375-36c8-4d6c-816c-2efdc93d2613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 31s 138ms/step - loss: 2.0053 - accuracy: 0.4317\n",
            "Test Loss: 2.0053277015686035\n",
            "Test Accuracy: 0.4317358732223511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "y_pred = np.argmax(model.predict(X_test), axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC0MhAqr9E50",
        "outputId": "8e6cd561-6b1a-441f-8a1b-4c559448b13f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 20s 90ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate classification report\n",
        "target_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxERbxSb9Rul",
        "outputId": "7ca50c07-aa2a-42a1-8700-545757fd46de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.32      0.30      0.31       985\n",
            "     Disgust       0.12      0.12      0.12       102\n",
            "        Fear       0.28      0.26      0.27      1043\n",
            "       Happy       0.64      0.65      0.64      1765\n",
            "         Sad       0.32      0.41      0.36      1210\n",
            "    Surprise       0.58      0.58      0.58       795\n",
            "     Neutral       0.41      0.33      0.37      1278\n",
            "\n",
            "    accuracy                           0.43      7178\n",
            "   macro avg       0.38      0.38      0.38      7178\n",
            "weighted avg       0.43      0.43      0.43      7178\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assume 'model' is your trained EmoNet model\n",
        "model_path = '/content/drive/MyDrive/EmoNetModel.pickle'\n",
        "\n",
        "# Save the model as a pickle file\n",
        "with open(model_path, 'wb') as f:\n",
        "    pickle.dump(model, f)\n"
      ],
      "metadata": {
        "id": "u-DYGhNDbwEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the model from the pickle file\n",
        "with open(model_path, 'rb') as f:\n",
        "    model = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "XJ1jfmWDcR_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pickle\n",
        "\n",
        "# Assuming 'model' is the loaded model\n",
        "# Save the loaded model as a pickle file\n",
        "loaded_model_path = '/content/drive/MyDrive/LoadedModel.pickle'\n",
        "\n",
        "with open(loaded_model_path, 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "# Download the pickle file\n",
        "files.download(loaded_model_path)\n"
      ],
      "metadata": {
        "id": "_KD1fQUJdN8u",
        "outputId": "28572526-23eb-48be-efe1-94e03ca616f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c68a3d27-3b15-4e06-9424-b5477cd1b33a\", \"LoadedModel.pickle\", 17469476)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}